# üìö Glosario de Web Scraping

Un diccionario completo de t√©rminos, conceptos y acr√≥nimos utilizados en web scraping y tecnolog√≠as relacionadas.

---

## A

### **API (Application Programming Interface)**
Conjunto de reglas y protocolos que permite a diferentes aplicaciones comunicarse entre s√≠. En web scraping, las APIs son preferibles al scraping cuando est√°n disponibles.

### **AJAX (Asynchronous JavaScript and XML)**
Tecnolog√≠a que permite a las p√°ginas web actualizar contenido din√°micamente sin recargar toda la p√°gina. Complica el web scraping tradicional ya que el contenido se carga despu√©s del HTML inicial.

### **Anti-bot**
Medidas t√©cnicas implementadas por sitios web para detectar y bloquear bots automatizados, incluyendo scrapers.

### **Atributo HTML**
Informaci√≥n adicional asociada a elementos HTML (ej: `class`, `id`, `href`, `data-*`). Son fundamentales para localizar elementos durante el scraping.

### **Autenticaci√≥n**
Proceso de verificar la identidad de un usuario o bot. En web scraping puede incluir login con credenciales, tokens API, o cookies de sesi√≥n.

---

## B

### **BeautifulSoup**
Biblioteca de Python para parsear documentos HTML y XML. Una de las herramientas m√°s populares para web scraping b√°sico e intermedio.

### **Bot**
Programa automatizado que realiza tareas repetitivas en internet. Los web scrapers son un tipo espec√≠fico de bot.

### **Browser Engine**
Motor que renderiza p√°ginas web (ej: Chromium, Gecko, WebKit). Selenium usa estos motores para scraping de contenido din√°mico.

---

## C

### **CAPTCHA (Completely Automated Public Turing test)**
Sistema de desaf√≠o-respuesta para determinar si el usuario es humano. M√©todo com√∫n anti-bot que complica el scraping automatizado.

### **Cookies**
Peque√±os archivos de texto que los sitios web almacenan en el navegador para recordar informaci√≥n. Importantes para mantener sesiones en scraping.

### **Crawling**
Proceso sistem√°tico de navegar y explorar sitios web siguiendo enlaces. Diferente del scraping, que se enfoca en extraer datos espec√≠ficos.

### **CSS Selectors**
Patrones utilizados para seleccionar elementos HTML basados en sus atributos, posici√≥n o relaciones. Ejemplo: `.class`, `#id`, `div > p`.

### **CSRF (Cross-Site Request Forgery)**
Tipo de ataque web. Los tokens CSRF protegen formularios y pueden requerir manejo especial en scraping.

---

## D

### **DOM (Document Object Model)**
Representaci√≥n estructurada de un documento HTML como √°rbol jer√°rquico. Los scrapers navegan por el DOM para extraer datos.

### **Dynamic Content**
Contenido web generado o modificado por JavaScript despu√©s de que se carga la p√°gina inicial. Requiere herramientas como Selenium para ser scrapeado.

---

## E

### **Encoding**
Sistema para representar caracteres de texto (ej: UTF-8, ISO-8859-1). Importante para manejar correctamente caracteres especiales en diferentes idiomas.

### **Endpoint**
URL espec√≠fica de una API que acepta requests y devuelve datos. En scraping, preferible a extraer datos directamente del HTML.

---

## F

### **Forms**
Elementos HTML que permiten a usuarios enviar datos. En scraping pueden requerir manejo especial para env√≠o de informaci√≥n.

### **Framework**
Conjunto de herramientas y librer√≠as que facilitan el desarrollo. Scrapy es un framework espec√≠fico para web scraping.

---

## G

### **GET Request**
M√©todo HTTP para solicitar datos de un servidor. El tipo m√°s com√∫n de request en web scraping b√°sico.

### **GDPR (General Data Protection Regulation)**
Regulaci√≥n europea sobre protecci√≥n de datos personales que afecta el scraping de informaci√≥n de ciudadanos de la UE.

---

## H

### **Headers HTTP**
Metadatos que acompa√±an requests y responses HTTP. Incluyen informaci√≥n como User-Agent, cookies, y tipo de contenido.

### **HTML (HyperText Markup Language)**
Lenguaje de marcado est√°ndar para crear p√°ginas web. Los scrapers parsean HTML para extraer informaci√≥n estructurada.

### **HTTP Status Codes**
C√≥digos num√©ricos que indican el resultado de un request HTTP:
- 200: √âxito
- 404: No encontrado
- 429: Too Many Requests
- 403: Prohibido

---

## I

### **iframe**
Elemento HTML que incrusta otra p√°gina web dentro de la actual. Puede complicar el scraping ya que el contenido est√° en un contexto diferente.

### **IP Blocking**
T√©cnica anti-bot que bloquea direcciones IP espec√≠ficas despu√©s de detectar comportamiento sospechoso.

---

## J

### **JavaScript**
Lenguaje de programaci√≥n que permite interactividad en p√°ginas web. Sitios con mucho JavaScript requieren herramientas especiales para scraping.

### **JSON (JavaScript Object Notation)**
Formato ligero de intercambio de datos. Muchas APIs devuelven datos en JSON, m√°s f√°cil de procesar que HTML.

---

## L

### **Latency**
Tiempo de retraso entre enviar un request y recibir la respuesta. Factor importante en la eficiencia del scraping.

### **Logging**
Registro sistem√°tico de eventos durante la ejecuci√≥n. Esencial para debugging y monitoreo de scrapers.

---

## M

### **Middleware**
Componente que procesa requests/responses entre el scraper y el sitio web. En Scrapy, permite implementar funcionalidades como proxies y rate limiting.

### **Mock Data**
Datos ficticios utilizados para testing. √ötiles para probar scrapers sin hacer requests reales.

---

## N

### **NoSQL**
Tipo de base de datos no relacional. √ötil para almacenar datos no estructurados obtenidos por scraping.

---

## O

### **OAuth**
Protocolo de autorizaci√≥n que permite acceso seguro a APIs. Alternativa segura al scraping para datos de servicios como Twitter o Facebook.

---

## P

### **Pagination**
Divisi√≥n de contenido en m√∫ltiples p√°ginas. Scrapers deben manejar paginaci√≥n para obtener datos completos.

### **Parser**
Componente que analiza y estructura datos de texto (como HTML). BeautifulSoup incluye varios parsers (html.parser, lxml, html5lib).

### **POST Request**
M√©todo HTTP para enviar datos al servidor. Usado en formularios y a menudo requerido para acceder a contenido espec√≠fico.

### **Proxy**
Servidor intermediario entre el scraper y el sitio objetivo. Usado para ocultar IP real y evitar bloqueos.

---

## Q

### **Query Parameters**
Par√°metros a√±adidos a URLs para modificar el contenido devuelto (ej: `?page=2&limit=10`). Importantes para navegar APIs y sitios din√°micos.

---

## R

### **Rate Limiting**
T√©cnica para controlar la frecuencia de requests. Implementada tanto por scrapers (para ser respetuosos) como por sitios web (para protecci√≥n).

### **Regex (Regular Expressions)**
Patrones para buscar y extraer texto espec√≠fico. √ötil para limpiar y procesar datos extra√≠dos.

### **robots.txt**
Archivo que especifica qu√© partes de un sitio web pueden ser accedidas por bots. Ubicado en `/robots.txt` de la ra√≠z del sitio.

---

## S

### **Scrapy**
Framework de Python especializado para web scraping a gran escala. Incluye manejo de concurrencia, middlewares, y pipelines.

### **Scraping**
Proceso de extraer datos de sitios web de forma automatizada.

### **Selenium**
Herramienta que automatiza navegadores web. Permite scraping de contenido JavaScript y simulaci√≥n de interacciones de usuario.

### **Session**
Estado persistente entre m√∫ltiples requests HTTP. Importante para mantener login y cookies durante scraping.

### **SPA (Single Page Application)**
Aplicaci√≥n web que carga din√°micamente contenido sin cambiar de p√°gina. Complica el scraping tradicional.

---

## T

### **Tags HTML**
Elementos estructurales de HTML (ej: `<div>`, `<p>`, `<a>`). Los scrapers buscan tags espec√≠ficos para extraer informaci√≥n.

### **Timeout**
Tiempo m√°ximo de espera para una operaci√≥n. Importante configurar timeouts apropiados para evitar que scrapers se cuelguen.

---

## U

### **URL (Uniform Resource Locator)**
Direcci√≥n web que identifica recursos en internet. Los scrapers navegan por URLs para acceder a diferentes contenidos.

### **User-Agent**
String que identifica el navegador o cliente haciendo el request. Scrapers deben usar User-Agents realistas para evitar detecci√≥n.

---

## V

### **Virtual Environment**
Entorno aislado de Python que permite instalar dependencias espec√≠ficas sin afectar el sistema global.

---

## W

### **Web Driver**
Interfaz que permite control program√°tico de navegadores web. Usado por Selenium para automatizar acciones de usuario.

---

## X

### **XML (eXtensible Markup Language)**
Formato de marcado estructurado similar a HTML. Algunos sitios devuelven datos en XML que debe ser parseado.

### **XPath (XML Path Language)**
Lenguaje para seleccionar nodos en documentos XML/HTML usando rutas tipo filesystem. M√°s potente que CSS selectors para navegaci√≥n compleja.

---

## T√©rminos T√©cnicos Espec√≠ficos

### **Backoff**
Estrategia de incrementar gradualmente los delays entre requests despu√©s de errores o rate limiting.

### **Circuit Breaker**
Patr√≥n que detiene temporalmente requests a un servicio que est√° fallando para evitar sobrecarga.

### **ETL (Extract, Transform, Load)**
Proceso de extracci√≥n, transformaci√≥n y carga de datos. Web scraping es t√≠picamente la fase de extracci√≥n.

### **Headless Browser**
Navegador que opera sin interfaz gr√°fica. M√°s eficiente para scraping ya que no renderiza elementos visuales.

### **Pipeline**
Serie de procesadores que transforman datos secuencialmente. En Scrapy, los pipelines procesan items extra√≠dos.

### **Spider**
En Scrapy, clase que define c√≥mo extraer datos de un sitio espec√≠fico. Cada spider maneja un dominio o tipo de contenido.

---

## C√≥digos de Estado HTTP Importantes

- **200 OK**: Request exitoso
- **301/302**: Redirecci√≥n permanente/temporal
- **403 Forbidden**: Acceso prohibido
- **404 Not Found**: P√°gina no encontrada
- **429 Too Many Requests**: Rate limit excedido
- **500 Internal Server Error**: Error del servidor
- **503 Service Unavailable**: Servicio no disponible

---

## Extensiones de Archivo Comunes

- **.py**: Archivo Python
- **.html/.htm**: Documento HTML
- **.xml**: Documento XML
- **.json**: Datos en formato JSON
- **.csv**: Datos separados por comas
- **.log**: Archivo de registro
- **.db/.sqlite**: Base de datos SQLite

---

## Bibliotecas de Python Relacionadas

### **Core Scraping**
- `requests`: HTTP requests
- `beautifulsoup4`: Parsing HTML/XML
- `lxml`: Parser XML/HTML r√°pido
- `scrapy`: Framework completo
- `selenium`: Automatizaci√≥n de navegador

### **Procesamiento de Datos**
- `pandas`: An√°lisis de datos
- `numpy`: Computaci√≥n num√©rica
- `json`: Manejo de JSON
- `csv`: Manejo de CSV
- `re`: Expresiones regulares

### **Base de Datos**
- `sqlite3`: SQLite (incluida en Python)
- `pymongo`: MongoDB
- `sqlalchemy`: ORM para bases de datos relacionales

### **Utilidades**
- `time`: Manejo de tiempo y delays
- `random`: Generaci√≥n de n√∫meros aleatorios
- `logging`: Sistema de logging
- `urllib`: Utilidades de URL
- `fake-useragent`: User agents aleatorios

---

## Patrones de Dise√±o Comunes

### **Singleton Pattern**
Un scraper que mantiene una √∫nica conexi√≥n de base de datos.

### **Factory Pattern**
Crear diferentes tipos de scrapers basados en el dominio objetivo.

### **Observer Pattern**
Notificar cuando se extraen ciertos tipos de datos.

### **Strategy Pattern**
Diferentes estrategias de scraping para diferentes tipos de sitios.

---

## M√©tricas de Rendimiento

### **Throughput**
N√∫mero de p√°ginas/items procesados por unidad de tiempo.

### **Success Rate**
Porcentaje de requests exitosos vs totales.

### **Response Time**
Tiempo promedio para completar un request.

### **Error Rate**
Porcentaje de requests que resultan en error.

---

Este glosario se actualiza regularmente con nuevos t√©rminos y conceptos. ¬øEncontraste un t√©rmino que no est√° incluido? ¬°Contribuye al glosario!