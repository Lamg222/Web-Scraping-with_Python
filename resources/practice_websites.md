# üåê Sitios Web Para Practicar Web Scraping

Una lista curada de sitios web seguros y √©ticos donde puedes practicar t√©cnicas de web scraping.

## üéØ Sitios Espec√≠ficamente para Scraping

### üìö Principiantes - Contenido Est√°tico

#### [Quotes to Scrape](http://quotes.toscrape.com/)
- **URL**: http://quotes.toscrape.com/
- **Nivel**: üü¢ Principiante
- **Contenido**: Citas famosas con autor y tags
- **T√©cnicas a practicar**:
  - Extracci√≥n b√°sica de texto
  - Navegaci√≥n por p√°ginas
  - Manejo de atributos
  - CSS selectors y XPath

```python
# Ejemplo r√°pido
import requests
from bs4 import BeautifulSoup

response = requests.get('http://quotes.toscrape.com/')
soup = BeautifulSoup(response.content, 'html.parser')

for quote in soup.find_all('div', class_='quote'):
    text = quote.find('span', class_='text').text
    author = quote.find('small', class_='author').text
    print(f"{text} - {author}")
```

#### [Books to Scrape](http://books.toscrape.com/)
- **URL**: http://books.toscrape.com/
- **Nivel**: üü¢ Principiante
- **Contenido**: Cat√°logo de libros con precios y valoraciones
- **T√©cnicas a practicar**:
  - Extracci√≥n de productos
  - Manejo de precios y n√∫meros
  - Navegaci√≥n por categor√≠as
  - Paginaci√≥n

#### [Scrape This Site](https://scrapethissite.com/)
- **URL**: https://scrapethissite.com/
- **Nivel**: üü¢ Principiante a üü° Intermedio
- **Contenido**: M√∫ltiples sandboxes tem√°ticos
- **Sandboxes incluidos**:
  - Pa√≠ses del mundo
  - Hockey teams
  - Oscar winning films
  - Turtle racing

### üîß Intermedios - Contenido Din√°mico

#### [ToScrape with JavaScript](http://quotes.toscrape.com/js/)
- **URL**: http://quotes.toscrape.com/js/
- **Nivel**: üü° Intermedio
- **Contenido**: Versi√≥n JavaScript de Quotes to Scrape
- **T√©cnicas a practicar**:
  - Selenium WebDriver
  - Esperas din√°micas
  - Manejo de AJAX

#### [Infinite Scroll](http://quotes.toscrape.com/scroll)
- **URL**: http://quotes.toscrape.com/scroll
- **Nivel**: üü° Intermedio
- **Contenido**: Scroll infinito con carga din√°mica
- **T√©cnicas a practicar**:
  - Scroll automatizado
  - Detecci√≥n de carga de contenido
  - APIs de JavaScript

### üéì Avanzados - Desaf√≠os Complejos

#### [Login Required](http://quotes.toscrape.com/login)
- **URL**: http://quotes.toscrape.com/login
- **Nivel**: üî¥ Avanzado
- **Contenido**: Contenido que requiere autenticaci√≥n
- **T√©cnicas a practicar**:
  - Manejo de sesiones
  - Formularios de login
  - Cookies y autenticaci√≥n

## üè™ E-commerce y Productos (Para uso educativo √∫nicamente)

### Sitios que permiten scraping educativo

#### [Fake Store API](https://fakestoreapi.com/)
- **URL**: https://fakestoreapi.com/
- **Tipo**: API REST (no scraping requerido)
- **Contenido**: Productos ficticios de e-commerce
- **Uso**: Practicar consumo de APIs

#### [JSONPlaceholder](https://jsonplaceholder.typicode.com/)
- **URL**: https://jsonplaceholder.typicode.com/
- **Tipo**: API REST de prueba
- **Contenido**: Posts, usuarios, comentarios ficticios
- **Uso**: Practicar consumo de APIs REST

## üì∞ Noticias y Blogs

### ‚ö†Ô∏è IMPORTANTE: Siempre revisar robots.txt y t√©rminos de uso

#### [Hacker News](https://news.ycombinator.com/)
- **URL**: https://news.ycombinator.com/
- **Contenido**: Noticias de tecnolog√≠a
- **robots.txt**: Permitido para bots educativos
- **T√©cnicas a practicar**:
  - Extracci√≥n de t√≠tulos y enlaces
  - Manejo de votaciones
  - Navegaci√≥n por p√°ginas

#### [Reddit (p√∫blic content)](https://www.reddit.com/)
- **URL**: https://www.reddit.com/
- **API**: https://www.reddit.com/dev/api/
- **Recomendaci√≥n**: Usar la API oficial
- **T√©cnicas**: Autenticaci√≥n OAuth, rate limiting

## üèõÔ∏è Datos Gubernamentales

#### [Data.gov](https://www.data.gov/)
- **URL**: https://www.data.gov/
- **Contenido**: Datasets gubernamentales de EE.UU.
- **Formato**: Principalmente CSV y JSON
- **Uso**: M√°s para descarga directa que scraping

#### [OpenData de la UE](https://data.europa.eu/)
- **URL**: https://data.europa.eu/
- **Contenido**: Datos abiertos europeos
- **Formato**: M√∫ltiples formatos

## üé≠ Sitios de Testing Local

### Para configurar en tu entorno local

#### [HTTP Testing Service](https://httpbin.org/)
- **URL**: https://httpbin.org/
- **Uso**: Testing de requests HTTP
- **Caracter√≠sticas**: Endpoints para probar headers, cookies, etc.

```python
# Ejemplos de uso
requests.get('https://httpbin.org/html')     # HTML simple
requests.get('https://httpbin.org/json')     # Respuesta JSON
requests.get('https://httpbin.org/xml')      # Respuesta XML
```

#### [MockAPI](https://mockapi.io/)
- **URL**: https://mockapi.io/
- **Uso**: Crear APIs de prueba personalizadas
- **Caracter√≠sticas**: Datos ficticios personalizables

## üß™ Entornos de Sandbox

### Sitios para experimentar sin restricciones

#### [Scrapy Playground](https://scrapy.org/doc/)
- **Documentaci√≥n oficial**: https://docs.scrapy.org/
- **Tutoriales**: Incluye spiders de ejemplo
- **Uso**: Seguir tutoriales oficiales

#### [Selenium Testing Playground](https://the-internet.herokuapp.com/)
- **URL**: https://the-internet.herokuapp.com/
- **Contenido**: Varios casos de testing web
- **Casos incluidos**:
  - Login forms
  - Dropdown lists
  - Dynamic loading
  - File uploads
  - Hovers
  - Frames

## üì± APIs P√∫blicas (Alternativa al Scraping)

### Cuando el scraping no es necesario

#### [Public APIs](https://github.com/public-apis/public-apis)
- **GitHub**: Lista masiva de APIs p√∫blicas
- **Categor√≠as**: M√∫ltiples categor√≠as disponibles
- **Uso**: Alternativa mejor que el scraping

#### [API List](https://apilist.fun/)
- **URL**: https://apilist.fun/
- **Contenido**: APIs categorizadas y curadas
- **Filtros**: Por categor√≠a, autenticaci√≥n, CORS, etc.

## ‚öñÔ∏è Consideraciones Legales y √âticas

### ‚úÖ Buenas pr√°cticas

1. **Revisar robots.txt**
   ```
   https://sitio-web.com/robots.txt
   ```

2. **Leer t√©rminos de servicio**
   - Buscar secciones sobre scraping/automation
   - Respetar restricciones

3. **Implementar rate limiting**
   ```python
   import time
   time.sleep(1)  # Pausa entre requests
   ```

4. **Usar User-Agent apropiado**
   ```python
   headers = {
       'User-Agent': 'Mozilla/5.0 (Educational Bot)'
   }
   ```

### ‚ùå Evitar

- Scraping de sitios que lo proh√≠ben expl√≠citamente
- Sobrecargar servidores con requests masivos
- Scraping de datos personales sin permiso
- Violaci√≥n de derechos de autor

## üõ†Ô∏è Herramientas de Desarrollo

### Para probar selectores

#### [CSS Selector Tester](https://www.w3schools.com/cssref/trysel.asp)
- Probar selectores CSS online

#### [XPath Tester](https://www.freeformatter.com/xpath-tester.html)
- Probar expresiones XPath

#### [Regex101](https://regex101.com/)
- Probar expresiones regulares

## üìö Conjuntos de Datos para Pr√°ctica

### Datasets est√°ticos

#### [Awesome Public Datasets](https://github.com/awesomedata/awesome-public-datasets)
- **GitHub**: Lista curada de datasets p√∫blicos
- **Formato**: CSV, JSON, XML
- **Uso**: Practicar procesamiento de datos

#### [Kaggle Datasets](https://www.kaggle.com/datasets)
- **URL**: https://www.kaggle.com/datasets
- **Contenido**: Miles de datasets
- **Formato**: Principalmente CSV
- **Uso**: An√°lisis de datos post-scraping

## üèÜ Desaf√≠os Progresivos

### Nivel 1: Principiante
1. Extraer todas las citas de quotes.toscrape.com
2. Crear un CSV con libros de books.toscrape.com
3. Obtener datos de pa√≠ses de scrapethissite.com

### Nivel 2: Intermedio
1. Scraping con paginaci√≥n autom√°tica
2. Manejo de formularios simples
3. Extracci√≥n de datos de tablas complejas

### Nivel 3: Avanzado
1. Scraping de contenido con JavaScript
2. Manejo de autenticaci√≥n
3. Scraping distribuido/concurrente

## üí° Consejos Pro

1. **Empezar simple**: Comienza con sitios est√°ticos
2. **Usar herramientas del navegador**: DevTools para inspeccionar
3. **Probar selectores**: Usar console del navegador
4. **Documentar hallazgos**: Guardar patrones √∫tiles
5. **Respetar l√≠mites**: No sobrecargar servidores

## üìû Recursos de Ayuda

- **Stack Overflow**: Tag `web-scraping`
- **Reddit**: r/webscraping
- **Discord**: Servers de Python y web scraping
- **GitHub**: Repositorios de ejemplo

---

‚ö†Ô∏è **Disclaimer**: Siempre verifica la legalidad y t√©rminos de uso antes de hacer scraping de cualquier sitio web. Esta lista es solo para prop√≥sitos educativos.