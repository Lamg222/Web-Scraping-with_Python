{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üéØ Lecci√≥n 9: XPath y CSS Selectors Avanzado\n",
    "\n",
    "## üéØ Objetivos de Aprendizaje\n",
    "\n",
    "Al finalizar esta lecci√≥n, ser√°s capaz de:\n",
    "- ‚úÖ Dominar el encadenamiento de selectores XPath\n",
    "- ‚úÖ Convertir entre XPath y CSS Selectors\n",
    "- ‚úÖ Utilizar selectores avanzados con Scrapy\n",
    "- ‚úÖ Implementar t√©cnicas de selecci√≥n complejas\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Encadenamiento de XPath üîó\n",
    "\n",
    "El encadenamiento de XPath es una t√©cnica poderosa que permite aplicar selectores de manera secuencial, dividiendo consultas complejas en partes m√°s manejables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalaci√≥n de bibliotecas necesarias\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "def instalar_scrapy():\n",
    "    \"\"\"Instala Scrapy si no est√° disponible\"\"\"\n",
    "    try:\n",
    "        import scrapy\n",
    "        print(\"‚úÖ Scrapy ya est√° instalado\")\n",
    "    except ImportError:\n",
    "        print(\"üì¶ Instalando Scrapy...\")\n",
    "        subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'scrapy', '--quiet'])\n",
    "        print(\"‚úÖ Scrapy instalado correctamente\")\n",
    "\n",
    "instalar_scrapy()\n",
    "\n",
    "from scrapy import Selector\n",
    "print(\"üéâ ¬°Listo para trabajar con selectores avanzados!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Principios del Encadenamiento\n",
    "\n",
    "Cuando usas Scrapy's `Selector` y `SelectorList`, puedes encadenar m√©todos `xpath()` aplic√°ndolos secuencialmente. La clave es usar un punto (`.`) al inicio de cada XPath subsiguiente para indicar que es relativo al contexto actual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HTML de ejemplo para demostrar encadenamiento\n",
    "html_ejemplo = \"\"\"\n",
    "<html>\n",
    "  <body>\n",
    "    <div class=\"container\">\n",
    "      <div class=\"articulo\" id=\"art1\">\n",
    "        <h2>T√≠tulo del Art√≠culo 1</h2>\n",
    "        <div class=\"contenido\">\n",
    "          <p class=\"intro\">Introducci√≥n del primer art√≠culo.</p>\n",
    "          <p>Contenido principal del art√≠culo.</p>\n",
    "          <span class=\"autor\">Juan P√©rez</span>\n",
    "        </div>\n",
    "      </div>\n",
    "      <div class=\"articulo\" id=\"art2\">\n",
    "        <h2>T√≠tulo del Art√≠culo 2</h2>\n",
    "        <div class=\"contenido\">\n",
    "          <p class=\"intro\">Introducci√≥n del segundo art√≠culo.</p>\n",
    "          <p>Otro contenido interesante.</p>\n",
    "          <span class=\"autor\">Mar√≠a Garc√≠a</span>\n",
    "        </div>\n",
    "      </div>\n",
    "    </div>\n",
    "  </body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "# Crear objeto Selector\n",
    "sel = Selector(text=html_ejemplo)\n",
    "\n",
    "print(\"üîç DEMOSTRACI√ìN DE ENCADENAMIENTO XPATH\\n\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# M√©todo 1: XPath completo (sin encadenamiento)\n",
    "print(\"\\n1Ô∏è‚É£ XPath completo sin encadenamiento:\")\n",
    "resultado1 = sel.xpath('//div[@class=\"articulo\"]/div[@class=\"contenido\"]/p[@class=\"intro\"]/text()').extract()\n",
    "print(f\"   Resultado: {resultado1}\")\n",
    "\n",
    "# M√©todo 2: XPath encadenado (m√°s modular)\n",
    "print(\"\\n2Ô∏è‚É£ XPath encadenado (m√°s legible y modular):\")\n",
    "articulos = sel.xpath('//div[@class=\"articulo\"]')\n",
    "print(f\"   - Art√≠culos encontrados: {len(articulos)}\")\n",
    "\n",
    "contenidos = articulos.xpath('./div[@class=\"contenido\"]')\n",
    "print(f\"   - Contenidos encontrados: {len(contenidos)}\")\n",
    "\n",
    "intros = contenidos.xpath('./p[@class=\"intro\"]/text()')\n",
    "resultado2 = intros.extract()\n",
    "print(f\"   - Textos de introducci√≥n: {resultado2}\")\n",
    "\n",
    "# Verificar que ambos m√©todos dan el mismo resultado\n",
    "print(f\"\\n‚úÖ ¬øAmbos m√©todos dan el mismo resultado? {resultado1 == resultado2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Ventajas del Encadenamiento\n",
    "\n",
    "El encadenamiento ofrece varias ventajas importantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ventaja 1: Reutilizaci√≥n de selectores\n",
    "print(\"üîÑ VENTAJA 1: REUTILIZACI√ìN DE SELECTORES\\n\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Seleccionar todos los art√≠culos una vez\n",
    "articulos = sel.xpath('//div[@class=\"articulo\"]')\n",
    "\n",
    "# Reutilizar para diferentes extracciones\n",
    "for i, articulo in enumerate(articulos, 1):\n",
    "    titulo = articulo.xpath('./h2/text()').extract_first()\n",
    "    autor = articulo.xpath('.//span[@class=\"autor\"]/text()').extract_first()\n",
    "    num_parrafos = len(articulo.xpath('.//p'))\n",
    "    \n",
    "    print(f\"\\nüìÑ Art√≠culo {i}:\")\n",
    "    print(f\"   T√≠tulo: {titulo}\")\n",
    "    print(f\"   Autor: {autor}\")\n",
    "    print(f\"   P√°rrafos: {num_parrafos}\")\n",
    "\n",
    "# Ventaja 2: Debugging m√°s f√°cil\n",
    "print(\"\\n\\nüêõ VENTAJA 2: DEBUGGING M√ÅS F√ÅCIL\\n\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Puedes verificar cada paso del encadenamiento\n",
    "paso1 = sel.xpath('//div[@class=\"container\"]')\n",
    "print(f\"Paso 1 - Container encontrado: {len(paso1) > 0}\")\n",
    "\n",
    "paso2 = paso1.xpath('./div[@class=\"articulo\"]')\n",
    "print(f\"Paso 2 - Art√≠culos encontrados: {len(paso2)}\")\n",
    "\n",
    "paso3 = paso2.xpath('./h2/text()')\n",
    "print(f\"Paso 3 - T√≠tulos extra√≠dos: {paso3.extract()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Ejercicios Pr√°cticos de Encadenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejercicio 1: Encadenar para obtener autores de art√≠culos espec√≠ficos\n",
    "print(\"üìù EJERCICIO 1: ENCADENAMIENTO SELECTIVO\\n\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Objetivo: Obtener el autor del art√≠culo con id=\"art1\"\n",
    "# Soluci√≥n con encadenamiento:\n",
    "articulo1 = sel.xpath('//div[@id=\"art1\"]')\n",
    "autor1 = articulo1.xpath('.//span[@class=\"autor\"]/text()').extract_first()\n",
    "print(f\"Autor del art√≠culo 1: {autor1}\")\n",
    "\n",
    "# Ejercicio 2: Encadenamiento m√∫ltiple\n",
    "print(\"\\nüìù EJERCICIO 2: ENCADENAMIENTO M√öLTIPLE\\n\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Objetivo: Obtener todos los p√°rrafos que NO tienen clase \"intro\"\n",
    "contenidos = sel.xpath('//div[@class=\"contenido\"]')\n",
    "parrafos_normales = contenidos.xpath('./p[not(@class=\"intro\")]/text()')\n",
    "print(f\"P√°rrafos sin clase 'intro': {parrafos_normales.extract()}\")\n",
    "\n",
    "# Ejercicio 3: Comparaci√≥n de m√©todos\n",
    "print(\"\\nüìù EJERCICIO 3: COMPARACI√ìN DE M√âTODOS\\n\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# M√©todo A: XPath directo\n",
    "metodo_a = sel.xpath('//div/span/p[3]')\n",
    "\n",
    "# M√©todo B: XPath encadenado equivalente\n",
    "metodo_b = sel.xpath('//div').xpath('./span/p[3]')\n",
    "\n",
    "print(\"‚úÖ Ambos m√©todos son equivalentes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Conversi√≥n entre XPath y CSS Selectors üîÑ\n",
    "\n",
    "Aunque XPath y CSS Selectors tienen sintaxis diferentes, a menudo puedes lograr los mismos resultados con ambos. Aprender a convertir entre ellos es una habilidad valiosa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HTML para ejemplos de conversi√≥n\n",
    "html_conversion = \"\"\"\n",
    "<html>\n",
    "  <body>\n",
    "    <div id=\"header\" class=\"top-section\">\n",
    "      <h1>T√≠tulo Principal</h1>\n",
    "      <nav>\n",
    "        <ul class=\"menu\">\n",
    "          <li><a href=\"#home\">Inicio</a></li>\n",
    "          <li><a href=\"#about\">Acerca de</a></li>\n",
    "          <li><a href=\"#contact\">Contacto</a></li>\n",
    "        </ul>\n",
    "      </nav>\n",
    "    </div>\n",
    "    <main>\n",
    "      <article data-id=\"123\" class=\"post featured\">\n",
    "        <h2>Art√≠culo Destacado</h2>\n",
    "        <p>Primer p√°rrafo del art√≠culo.</p>\n",
    "        <p>Segundo p√°rrafo del art√≠culo.</p>\n",
    "      </article>\n",
    "      <article data-id=\"124\" class=\"post\">\n",
    "        <h2>Otro Art√≠culo</h2>\n",
    "        <p>Contenido del segundo art√≠culo.</p>\n",
    "      </article>\n",
    "    </main>\n",
    "  </body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "sel2 = Selector(text=html_conversion)\n",
    "\n",
    "print(\"üîÑ TABLA DE CONVERSIONES XPATH ‚Üî CSS\\n\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Diccionario de conversiones comunes\n",
    "conversiones = [\n",
    "    {\n",
    "        'descripcion': 'Elemento por ID',\n",
    "        'xpath': '//div[@id=\"header\"]',\n",
    "        'css': 'div#header',\n",
    "        'css_alt': '#header'  # Versi√≥n m√°s corta\n",
    "    },\n",
    "    {\n",
    "        'descripcion': 'Elemento por clase',\n",
    "        'xpath': '//ul[@class=\"menu\"]',\n",
    "        'css': 'ul.menu',\n",
    "        'css_alt': '.menu'  # Si solo hay un elemento con esa clase\n",
    "    },\n",
    "    {\n",
    "        'descripcion': 'Hijo directo',\n",
    "        'xpath': '//nav/ul',\n",
    "        'css': 'nav > ul',\n",
    "        'css_alt': None\n",
    "    },\n",
    "    {\n",
    "        'descripcion': 'Descendiente (cualquier nivel)',\n",
    "        'xpath': '//div//a',\n",
    "        'css': 'div a',\n",
    "        'css_alt': None\n",
    "    },\n",
    "    {\n",
    "        'descripcion': 'Primer elemento',\n",
    "        'xpath': '//li[1]',\n",
    "        'css': 'li:first-child',\n",
    "        'css_alt': 'li:nth-child(1)'\n",
    "    },\n",
    "    {\n",
    "        'descripcion': 'Atributo data',\n",
    "        'xpath': '//article[@data-id=\"123\"]',\n",
    "        'css': 'article[data-id=\"123\"]',\n",
    "        'css_alt': None\n",
    "    },\n",
    "    {\n",
    "        'descripcion': 'M√∫ltiples clases',\n",
    "        'xpath': '//article[@class=\"post featured\"]',\n",
    "        'css': 'article.post.featured',\n",
    "        'css_alt': None\n",
    "    }\n",
    "]\n",
    "\n",
    "# Mostrar tabla de conversiones y verificar resultados\n",
    "for conv in conversiones:\n",
    "    print(f\"\\nüìå {conv['descripcion']}\")\n",
    "    print(f\"   XPath: {conv['xpath']}\")\n",
    "    print(f\"   CSS:   {conv['css']}\")\n",
    "    if conv['css_alt']:\n",
    "        print(f\"   Alt:   {conv['css_alt']}\")\n",
    "    \n",
    "    # Verificar que ambos selectores dan el mismo resultado\n",
    "    resultado_xpath = sel2.xpath(conv['xpath']).extract()\n",
    "    resultado_css = sel2.css(conv['css']).extract()\n",
    "    \n",
    "    coinciden = len(resultado_xpath) == len(resultado_css)\n",
    "    print(f\"   ‚úÖ Resultados coinciden: {coinciden} (encontrados: {len(resultado_xpath)})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Casos Especiales de Conversi√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üéØ CASOS ESPECIALES DE CONVERSI√ìN\\n\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Caso 1: XPath puede hacer cosas que CSS no puede\n",
    "print(\"\\n1Ô∏è‚É£ Capacidades √∫nicas de XPath:\")\n",
    "print(\"   XPath puede:\")\n",
    "print(\"   ‚Ä¢ Seleccionar por texto: //p[text()='Contenido']\")\n",
    "print(\"   ‚Ä¢ Navegar hacia arriba: //span/parent::div\")\n",
    "print(\"   ‚Ä¢ Usar funciones: //p[contains(@class, 'intro')]\")\n",
    "print(\"   ‚Ä¢ Seleccionar atributos: //img/@src\")\n",
    "\n",
    "# Demostraci√≥n de selecci√≥n por texto (solo XPath)\n",
    "print(\"\\n   Ejemplo - Selecci√≥n por texto:\")\n",
    "xpath_texto = sel2.xpath('//p[contains(text(), \"Primer\")]/text()').extract()\n",
    "print(f\"   XPath resultado: {xpath_texto}\")\n",
    "print(\"   CSS: No es posible directamente\")\n",
    "\n",
    "# Caso 2: CSS es m√°s conciso para algunas tareas\n",
    "print(\"\\n2Ô∏è‚É£ Ventajas de CSS Selectors:\")\n",
    "print(\"   CSS es m√°s conciso para:\")\n",
    "print(\"   ‚Ä¢ Pseudo-selectores: :hover, :visited, :nth-of-type\")\n",
    "print(\"   ‚Ä¢ Combinaciones de clases: .clase1.clase2\")\n",
    "print(\"   ‚Ä¢ Selectores de atributos parciales: [href^='http']\")\n",
    "\n",
    "# Ejemplo de pseudo-selectores\n",
    "print(\"\\n   Ejemplo - Pseudo-selectores:\")\n",
    "css_primero = sel2.css('li:first-child a::text').extract_first()\n",
    "xpath_primero = sel2.xpath('//li[1]/a/text()').extract_first()\n",
    "print(f\"   CSS resultado: {css_primero}\")\n",
    "print(f\"   XPath resultado: {xpath_primero}\")\n",
    "\n",
    "# Caso 3: Conversiones complejas\n",
    "print(\"\\n3Ô∏è‚É£ Conversiones Complejas:\")\n",
    "\n",
    "ejemplos_complejos = [\n",
    "    {\n",
    "        'caso': 'Hermano siguiente',\n",
    "        'xpath': '//h2/following-sibling::p[1]',\n",
    "        'css': 'h2 + p'\n",
    "    },\n",
    "    {\n",
    "        'caso': 'Atributo que empieza con',\n",
    "        'xpath': '//a[starts-with(@href, \"#\")]',\n",
    "        'css': 'a[href^=\"#\"]'\n",
    "    },\n",
    "    {\n",
    "        'caso': 'Atributo que contiene',\n",
    "        'xpath': '//article[contains(@class, \"post\")]',\n",
    "        'css': 'article[class*=\"post\"]'\n",
    "    }\n",
    "]\n",
    "\n",
    "for ejemplo in ejemplos_complejos:\n",
    "    print(f\"\\n   {ejemplo['caso']}:\")\n",
    "    print(f\"      XPath: {ejemplo['xpath']}\")\n",
    "    print(f\"      CSS:   {ejemplo['css']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Integraci√≥n con Scrapy Requests üåê\n",
    "\n",
    "Scrapy permite combinar requests HTTP con selectores de manera eficiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from scrapy import Selector\n",
    "\n",
    "def scraper_con_scrapy_selector(url):\n",
    "    \"\"\"\n",
    "    Ejemplo de c√≥mo usar Scrapy Selector con requests\n",
    "    para hacer web scraping sin un proyecto Scrapy completo.\n",
    "    \"\"\"\n",
    "    print(f\"üåê SCRAPING CON SCRAPY SELECTOR\\n\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"URL: {url}\\n\")\n",
    "    \n",
    "    try:\n",
    "        # Paso 1: Obtener el HTML con requests\n",
    "        headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'\n",
    "        }\n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        print(f\"‚úÖ Respuesta recibida: {response.status_code}\")\n",
    "        print(f\"üìè Tama√±o del HTML: {len(response.content)} bytes\\n\")\n",
    "        \n",
    "        # Paso 2: Crear Selector de Scrapy\n",
    "        sel = Selector(text=response.text)\n",
    "        \n",
    "        # Paso 3: Extraer informaci√≥n usando XPath y CSS\n",
    "        print(\"üìä EXTRACCI√ìN DE DATOS:\\n\")\n",
    "        \n",
    "        # T√≠tulo de la p√°gina\n",
    "        titulo = sel.xpath('//title/text()').extract_first()\n",
    "        print(f\"üìÑ T√≠tulo: {titulo}\")\n",
    "        \n",
    "        # Meta descripci√≥n\n",
    "        descripcion = sel.xpath('//meta[@name=\"description\"]/@content').extract_first()\n",
    "        if descripcion:\n",
    "            print(f\"üìù Descripci√≥n: {descripcion[:100]}...\")\n",
    "        \n",
    "        # Todos los encabezados h1\n",
    "        h1s = sel.css('h1::text').extract()\n",
    "        print(f\"\\nüî§ Encabezados H1 encontrados: {len(h1s)}\")\n",
    "        for i, h1 in enumerate(h1s[:3], 1):  # Primeros 3\n",
    "            print(f\"   {i}. {h1}\")\n",
    "        \n",
    "        # Enlaces\n",
    "        enlaces = sel.xpath('//a[@href]')\n",
    "        print(f\"\\nüîó Total de enlaces: {len(enlaces)}\")\n",
    "        \n",
    "        # Enlaces externos\n",
    "        enlaces_externos = sel.xpath('//a[starts-with(@href, \"http\")]/@href').extract()\n",
    "        print(f\"   ‚Ä¢ Enlaces externos: {len(enlaces_externos)}\")\n",
    "        \n",
    "        # Enlaces internos\n",
    "        enlaces_internos = sel.xpath('//a[starts-with(@href, \"/\") or starts-with(@href, \"#\")]/@href').extract()\n",
    "        print(f\"   ‚Ä¢ Enlaces internos: {len(enlaces_internos)}\")\n",
    "        \n",
    "        # Im√°genes\n",
    "        imagenes = sel.css('img::attr(src)').extract()\n",
    "        print(f\"\\nüñºÔ∏è Im√°genes encontradas: {len(imagenes)}\")\n",
    "        \n",
    "        # P√°rrafos\n",
    "        parrafos = sel.xpath('//p[string-length(text()) > 50]')\n",
    "        print(f\"\\nüìù P√°rrafos con m√°s de 50 caracteres: {len(parrafos)}\")\n",
    "        \n",
    "        return sel\n",
    "        \n",
    "    except requests.RequestException as e:\n",
    "        print(f\"‚ùå Error al obtener la p√°gina: {e}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error inesperado: {e}\")\n",
    "        return None\n",
    "\n",
    "# Probar con una p√°gina de ejemplo\n",
    "url_ejemplo = \"http://quotes.toscrape.com/\"\n",
    "selector = scraper_con_scrapy_selector(url_ejemplo)\n",
    "\n",
    "if selector:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"üéØ EJEMPLO ESPEC√çFICO: Extrayendo citas\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Extraer citas usando encadenamiento\n",
    "    citas = selector.css('div.quote')\n",
    "    print(f\"\\nüìö Citas encontradas: {len(citas)}\\n\")\n",
    "    \n",
    "    for i, cita in enumerate(citas[:3], 1):  # Primeras 3 citas\n",
    "        texto = cita.css('span.text::text').extract_first()\n",
    "        autor = cita.css('small.author::text').extract_first()\n",
    "        tags = cita.css('a.tag::text').extract()\n",
    "        \n",
    "        print(f\"Cita {i}:\")\n",
    "        print(f\"   üìù Texto: {texto[:60]}...\")\n",
    "        print(f\"   ‚úçÔ∏è Autor: {autor}\")\n",
    "        print(f\"   üè∑Ô∏è Tags: {', '.join(tags)}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. T√©cnicas Avanzadas de Selecci√≥n üéì\n",
    "\n",
    "### 4.1 Uso de Funciones XPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HTML con contenido diverso para t√©cnicas avanzadas\n",
    "html_avanzado = \"\"\"\n",
    "<html>\n",
    "  <body>\n",
    "    <div class=\"productos\">\n",
    "      <div class=\"producto\" data-precio=\"29.99\" data-stock=\"5\">\n",
    "        <h3>Producto A</h3>\n",
    "        <p class=\"descripcion\">Descripci√≥n del producto A con palabras clave importantes.</p>\n",
    "        <span class=\"precio\">$29.99</span>\n",
    "        <span class=\"disponibilidad\">En stock</span>\n",
    "      </div>\n",
    "      <div class=\"producto oferta\" data-precio=\"19.99\" data-stock=\"0\">\n",
    "        <h3>Producto B - Oferta</h3>\n",
    "        <p class=\"descripcion\">Este producto B est√° en oferta especial.</p>\n",
    "        <span class=\"precio\">$19.99</span>\n",
    "        <span class=\"disponibilidad\">Agotado</span>\n",
    "      </div>\n",
    "      <div class=\"producto nuevo\" data-precio=\"39.99\" data-stock=\"10\">\n",
    "        <h3>Producto C</h3>\n",
    "        <p class=\"descripcion\">Nuevo producto C reci√©n llegado.</p>\n",
    "        <span class=\"precio\">$39.99</span>\n",
    "        <span class=\"disponibilidad\">En stock</span>\n",
    "      </div>\n",
    "    </div>\n",
    "    <div class=\"comentarios\">\n",
    "      <div class=\"comentario\" data-rating=\"5\">\n",
    "        <p>Excelente producto, muy recomendado.</p>\n",
    "        <span class=\"autor\">Juan</span>\n",
    "      </div>\n",
    "      <div class=\"comentario\" data-rating=\"3\">\n",
    "        <p>Producto regular, cumple su funci√≥n.</p>\n",
    "        <span class=\"autor\">Mar√≠a</span>\n",
    "      </div>\n",
    "    </div>\n",
    "  </body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "sel_avanzado = Selector(text=html_avanzado)\n",
    "\n",
    "print(\"üéì T√âCNICAS AVANZADAS DE SELECCI√ìN CON XPATH\\n\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# 1. Funci√≥n contains()\n",
    "print(\"\\n1Ô∏è‚É£ Funci√≥n contains() - Buscar texto parcial:\")\n",
    "productos_oferta = sel_avanzado.xpath('//h3[contains(text(), \"Oferta\")]/text()').extract()\n",
    "print(f\"   Productos con 'Oferta' en el t√≠tulo: {productos_oferta}\")\n",
    "\n",
    "descripciones_nuevo = sel_avanzado.xpath('//p[contains(@class, \"descripcion\")][contains(text(), \"nuevo\")]/text()').extract()\n",
    "print(f\"   Descripciones que mencionan 'nuevo': {descripciones_nuevo}\")\n",
    "\n",
    "# 2. Funci√≥n starts-with()\n",
    "print(\"\\n2Ô∏è‚É£ Funci√≥n starts-with() - Buscar inicio de texto:\")\n",
    "productos_p = sel_avanzado.xpath('//h3[starts-with(text(), \"Producto\")]/text()').extract()\n",
    "print(f\"   Productos que empiezan con 'Producto': {productos_p}\")\n",
    "\n",
    "# 3. Funci√≥n position() y last()\n",
    "print(\"\\n3Ô∏è‚É£ Funciones position() y last() - Selecci√≥n por posici√≥n:\")\n",
    "primer_producto = sel_avanzado.xpath('//div[@class=\"producto\"][1]/h3/text()').extract_first()\n",
    "ultimo_producto = sel_avanzado.xpath('//div[@class=\"producto\"][last()]/h3/text()').extract_first()\n",
    "print(f\"   Primer producto: {primer_producto}\")\n",
    "print(f\"   √öltimo producto: {ultimo_producto}\")\n",
    "\n",
    "# 4. Funci√≥n not()\n",
    "print(\"\\n4Ô∏è‚É£ Funci√≥n not() - Exclusi√≥n de elementos:\")\n",
    "productos_disponibles = sel_avanzado.xpath('//div[@class=\"producto\"][not(@data-stock=\"0\")]/h3/text()').extract()\n",
    "print(f\"   Productos disponibles (stock > 0): {productos_disponibles}\")\n",
    "\n",
    "# 5. Operadores de comparaci√≥n\n",
    "print(\"\\n5Ô∏è‚É£ Operadores de comparaci√≥n - Filtros num√©ricos:\")\n",
    "# Nota: En XPath 1.0 (usado por lxml), las comparaciones num√©ricas son limitadas\n",
    "productos_baratos = sel_avanzado.xpath('//div[@data-precio < \"30\"]/h3/text()').extract()\n",
    "print(f\"   Productos con precio < $30: {productos_baratos}\")\n",
    "\n",
    "# 6. Funci√≥n normalize-space()\n",
    "print(\"\\n6Ô∏è‚É£ Funci√≥n normalize-space() - Limpiar espacios:\")\n",
    "textos_limpios = sel_avanzado.xpath('//p[normalize-space()]/text()').extract()\n",
    "print(f\"   P√°rrafos con contenido (sin espacios vac√≠os): {len(textos_limpios)} encontrados\")\n",
    "\n",
    "# 7. M√∫ltiples condiciones con and/or\n",
    "print(\"\\n7Ô∏è‚É£ Condiciones m√∫ltiples con and/or:\")\n",
    "productos_especiales = sel_avanzado.xpath(\n",
    "    '//div[@class=\"producto oferta\" or @class=\"producto nuevo\"]/h3/text()'\n",
    ").extract()\n",
    "print(f\"   Productos en oferta O nuevos: {productos_especiales}\")\n",
    "\n",
    "productos_disponibles_baratos = sel_avanzado.xpath(\n",
    "    '//div[@data-stock>\"0\" and @data-precio<\"30\"]/h3/text()'\n",
    ").extract()\n",
    "print(f\"   Productos disponibles Y baratos: {productos_disponibles_baratos}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Selectores CSS Avanzados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üé® SELECTORES CSS AVANZADOS\\n\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# 1. Pseudo-clases estructurales\n",
    "print(\"\\n1Ô∏è‚É£ Pseudo-clases estructurales:\")\n",
    "primer_producto_css = sel_avanzado.css('div.producto:first-child h3::text').extract_first()\n",
    "print(f\"   Primer producto (CSS): {primer_producto_css}\")\n",
    "\n",
    "ultimo_producto_css = sel_avanzado.css('div.producto:last-child h3::text').extract_first()\n",
    "print(f\"   √öltimo producto (CSS): {ultimo_producto_css}\")\n",
    "\n",
    "segundo_producto_css = sel_avanzado.css('div.producto:nth-child(2) h3::text').extract_first()\n",
    "print(f\"   Segundo producto (CSS): {segundo_producto_css}\")\n",
    "\n",
    "# 2. Selectores de atributos avanzados\n",
    "print(\"\\n2Ô∏è‚É£ Selectores de atributos CSS:\")\n",
    "productos_con_data = sel_avanzado.css('div[data-precio] h3::text').extract()\n",
    "print(f\"   Productos con atributo data-precio: {productos_con_data}\")\n",
    "\n",
    "productos_stock_5 = sel_avanzado.css('div[data-stock=\"5\"] h3::text').extract()\n",
    "print(f\"   Productos con stock = 5: {productos_stock_5}\")\n",
    "\n",
    "# 3. Combinadores\n",
    "print(\"\\n3Ô∏è‚É£ Combinadores CSS:\")\n",
    "precio_despues_h3 = sel_avanzado.css('h3 ~ span.precio::text').extract()\n",
    "print(f\"   Precios despu√©s de h3 (hermanos): {precio_despues_h3}\")\n",
    "\n",
    "precio_directo = sel_avanzado.css('div.producto > span.precio::text').extract()\n",
    "print(f\"   Precios hijos directos de producto: {precio_directo}\")\n",
    "\n",
    "# 4. M√∫ltiples clases\n",
    "print(\"\\n4Ô∏è‚É£ Selectores con m√∫ltiples clases:\")\n",
    "productos_oferta = sel_avanzado.css('div.producto.oferta h3::text').extract()\n",
    "print(f\"   Productos con clases 'producto' Y 'oferta': {productos_oferta}\")\n",
    "\n",
    "# 5. Pseudo-elementos\n",
    "print(\"\\n5Ô∏è‚É£ Pseudo-elementos ::text y ::attr():\")\n",
    "todos_textos = sel_avanzado.css('span.precio::text').extract()\n",
    "print(f\"   Todos los precios (texto): {todos_textos}\")\n",
    "\n",
    "todos_ratings = sel_avanzado.css('div.comentario::attr(data-rating)').extract()\n",
    "print(f\"   Ratings de comentarios (atributo): {todos_ratings}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Mejores Pr√°cticas y Optimizaci√≥n üöÄ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üöÄ MEJORES PR√ÅCTICAS PARA SELECTORES\\n\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Ejemplo de HTML complejo\n",
    "html_complejo = \"\"\"\n",
    "<div class=\"container main-content\" id=\"main\">\n",
    "    <article class=\"post featured\" data-id=\"123\">\n",
    "        <header>\n",
    "            <h2 class=\"title big-title\">T√≠tulo del Art√≠culo</h2>\n",
    "            <div class=\"meta\">\n",
    "                <span class=\"author\">Autor: Juan</span>\n",
    "                <span class=\"date\">2024-01-15</span>\n",
    "            </div>\n",
    "        </header>\n",
    "        <div class=\"content\">\n",
    "            <p>Contenido del art√≠culo...</p>\n",
    "        </div>\n",
    "    </article>\n",
    "</div>\n",
    "\"\"\"\n",
    "\n",
    "sel_practica = Selector(text=html_complejo)\n",
    "\n",
    "print(\"‚úÖ BUENAS PR√ÅCTICAS:\\n\")\n",
    "\n",
    "# 1. Ser lo m√°s espec√≠fico posible\n",
    "print(\"1Ô∏è‚É£ ESPECIFICIDAD:\")\n",
    "print(\"   ‚ùå Malo: //div//span\")\n",
    "print(\"   ‚úÖ Bueno: //div[@class='meta']/span[@class='author']\")\n",
    "print(\"   Raz√≥n: M√°s espec√≠fico = m√°s robusto a cambios\\n\")\n",
    "\n",
    "# 2. Preferir IDs cuando sea posible\n",
    "print(\"2Ô∏è‚É£ USAR IDs √öNICOS:\")\n",
    "print(\"   ‚ùå Malo: //div[@class='container main-content']\")\n",
    "print(\"   ‚úÖ Bueno: //div[@id='main']\")\n",
    "print(\"   Raz√≥n: IDs son √∫nicos y m√°s r√°pidos\\n\")\n",
    "\n",
    "# 3. Evitar selectores fr√°giles\n",
    "print(\"3Ô∏è‚É£ EVITAR POSICIONES ABSOLUTAS:\")\n",
    "print(\"   ‚ùå Malo: //div[1]/article[1]/header[1]/h2[1]\")\n",
    "print(\"   ‚úÖ Bueno: //article[@data-id='123']//h2[@class='title']\")\n",
    "print(\"   Raz√≥n: Las posiciones pueden cambiar\\n\")\n",
    "\n",
    "# 4. Usar atributos data cuando est√©n disponibles\n",
    "print(\"4Ô∏è‚É£ APROVECHAR ATRIBUTOS DATA:\")\n",
    "print(\"   ‚ùå Malo: //article[@class='post featured']\")\n",
    "print(\"   ‚úÖ Bueno: //article[@data-id='123']\")\n",
    "print(\"   Raz√≥n: Los data-* suelen ser m√°s estables\\n\")\n",
    "\n",
    "# 5. Combinar XPath y CSS seg√∫n convenga\n",
    "print(\"5Ô∏è‚É£ MEZCLAR XPATH Y CSS:\")\n",
    "print(\"   Para estructura: CSS ('article.post')\")\n",
    "print(\"   Para texto: XPath ('//span[contains(text(), \"Autor\")]')\")\n",
    "print(\"   Para navegaci√≥n: XPath ('//div/parent::article')\\n\")\n",
    "\n",
    "# Ejemplo pr√°ctico de optimizaci√≥n\n",
    "print(\"‚ö° EJEMPLO DE OPTIMIZACI√ìN:\\n\")\n",
    "\n",
    "import time\n",
    "\n",
    "# M√©todo lento (m√∫ltiples b√∫squedas)\n",
    "start = time.time()\n",
    "for _ in range(100):\n",
    "    titulo = sel_practica.xpath('//h2[@class=\"title big-title\"]/text()').extract_first()\n",
    "    autor = sel_practica.xpath('//span[@class=\"author\"]/text()').extract_first()\n",
    "    fecha = sel_practica.xpath('//span[@class=\"date\"]/text()').extract_first()\n",
    "tiempo_lento = time.time() - start\n",
    "\n",
    "# M√©todo r√°pido (una b√∫squeda, encadenamiento)\n",
    "start = time.time()\n",
    "for _ in range(100):\n",
    "    articulo = sel_practica.xpath('//article[@data-id=\"123\"]')[0]\n",
    "    titulo = articulo.xpath('.//h2/text()').extract_first()\n",
    "    autor = articulo.xpath('.//span[@class=\"author\"]/text()').extract_first()\n",
    "    fecha = articulo.xpath('.//span[@class=\"date\"]/text()').extract_first()\n",
    "tiempo_rapido = time.time() - start\n",
    "\n",
    "print(f\"‚è±Ô∏è M√©todo lento: {tiempo_lento:.4f}s\")\n",
    "print(f\"‚ö° M√©todo r√°pido: {tiempo_rapido:.4f}s\")\n",
    "print(f\"üöÄ Mejora: {((tiempo_lento - tiempo_rapido) / tiempo_lento * 100):.1f}% m√°s r√°pido\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Ejercicio Final: Scraper Completo üí™"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üí™ EJERCICIO FINAL: SCRAPER COMPLETO\\n\")\n",
    "print(\"=\"*70)\n",
    "print(\"Objetivo: Crear un scraper que use todas las t√©cnicas aprendidas\\n\")\n",
    "\n",
    "# HTML de un blog ficticio\n",
    "html_blog = \"\"\"\n",
    "<html>\n",
    "  <head>\n",
    "    <title>Mi Blog de Tecnolog√≠a</title>\n",
    "  </head>\n",
    "  <body>\n",
    "    <div id=\"content\">\n",
    "      <article class=\"post\" data-id=\"1\" data-category=\"python\">\n",
    "        <h2>Aprendiendo Web Scraping con Python</h2>\n",
    "        <div class=\"meta\">\n",
    "          <span class=\"author\">Juan P√©rez</span>\n",
    "          <span class=\"date\">2024-01-15</span>\n",
    "          <span class=\"reading-time\">5 min</span>\n",
    "        </div>\n",
    "        <div class=\"content\">\n",
    "          <p>El web scraping es una t√©cnica fundamental...</p>\n",
    "          <p>Python ofrece herramientas poderosas como Scrapy...</p>\n",
    "        </div>\n",
    "        <div class=\"tags\">\n",
    "          <a href=\"/tag/python\" class=\"tag\">Python</a>\n",
    "          <a href=\"/tag/scraping\" class=\"tag\">Scraping</a>\n",
    "          <a href=\"/tag/tutorial\" class=\"tag\">Tutorial</a>\n",
    "        </div>\n",
    "        <div class=\"interactions\">\n",
    "          <span class=\"likes\" data-count=\"42\">‚ù§Ô∏è 42</span>\n",
    "          <span class=\"comments\" data-count=\"8\">üí¨ 8</span>\n",
    "        </div>\n",
    "      </article>\n",
    "      \n",
    "      <article class=\"post featured\" data-id=\"2\" data-category=\"javascript\">\n",
    "        <h2>React vs Vue: Comparaci√≥n 2024</h2>\n",
    "        <div class=\"meta\">\n",
    "          <span class=\"author\">Mar√≠a Garc√≠a</span>\n",
    "          <span class=\"date\">2024-01-14</span>\n",
    "          <span class=\"reading-time\">8 min</span>\n",
    "        </div>\n",
    "        <div class=\"content\">\n",
    "          <p>En el mundo del desarrollo frontend...</p>\n",
    "          <p>React sigue dominando el mercado...</p>\n",
    "        </div>\n",
    "        <div class=\"tags\">\n",
    "          <a href=\"/tag/javascript\" class=\"tag\">JavaScript</a>\n",
    "          <a href=\"/tag/react\" class=\"tag\">React</a>\n",
    "          <a href=\"/tag/vue\" class=\"tag\">Vue</a>\n",
    "        </div>\n",
    "        <div class=\"interactions\">\n",
    "          <span class=\"likes\" data-count=\"156\">‚ù§Ô∏è 156</span>\n",
    "          <span class=\"comments\" data-count=\"23\">üí¨ 23</span>\n",
    "        </div>\n",
    "      </article>\n",
    "    </div>\n",
    "  </body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "def scraper_completo(html):\n",
    "    \"\"\"\n",
    "    Scraper que combina todas las t√©cnicas aprendidas:\n",
    "    - Encadenamiento de selectores\n",
    "    - Conversi√≥n XPath/CSS\n",
    "    - Funciones XPath avanzadas\n",
    "    - Optimizaci√≥n\n",
    "    \"\"\"\n",
    "    sel = Selector(text=html)\n",
    "    \n",
    "    # Estructura para almacenar datos\n",
    "    blog_data = {\n",
    "        'titulo_sitio': '',\n",
    "        'articulos': [],\n",
    "        'estadisticas': {}\n",
    "    }\n",
    "    \n",
    "    # 1. Informaci√≥n general del sitio\n",
    "    blog_data['titulo_sitio'] = sel.xpath('//title/text()').extract_first()\n",
    "    \n",
    "    # 2. Extraer art√≠culos usando encadenamiento\n",
    "    articulos = sel.css('article.post')\n",
    "    \n",
    "    for articulo in articulos:\n",
    "        # Usar encadenamiento para extraer datos\n",
    "        post_data = {}\n",
    "        \n",
    "        # Combinar XPath y CSS\n",
    "        post_data['id'] = articulo.css('::attr(data-id)').extract_first()\n",
    "        post_data['categoria'] = articulo.xpath('./@data-category').extract_first()\n",
    "        post_data['es_destacado'] = 'featured' in articulo.css('::attr(class)').extract_first()\n",
    "        \n",
    "        # Informaci√≥n del post\n",
    "        post_data['titulo'] = articulo.css('h2::text').extract_first()\n",
    "        \n",
    "        # Metadatos con XPath\n",
    "        meta = articulo.xpath('.//div[@class=\"meta\"]')\n",
    "        post_data['autor'] = meta.xpath('.//span[@class=\"author\"]/text()').extract_first()\n",
    "        post_data['fecha'] = meta.xpath('.//span[@class=\"date\"]/text()').extract_first()\n",
    "        post_data['tiempo_lectura'] = meta.xpath('.//span[@class=\"reading-time\"]/text()').extract_first()\n",
    "        \n",
    "        # Contenido\n",
    "        parrafos = articulo.css('div.content p::text').extract()\n",
    "        post_data['num_parrafos'] = len(parrafos)\n",
    "        post_data['preview'] = parrafos[0][:50] + '...' if parrafos else ''\n",
    "        \n",
    "        # Tags con CSS\n",
    "        post_data['tags'] = articulo.css('a.tag::text').extract()\n",
    "        \n",
    "        # Interacciones con funciones XPath\n",
    "        likes = articulo.xpath('.//span[@class=\"likes\"]/@data-count').extract_first()\n",
    "        comments = articulo.xpath('.//span[@class=\"comments\"]/@data-count').extract_first()\n",
    "        post_data['likes'] = int(likes) if likes else 0\n",
    "        post_data['comentarios'] = int(comments) if comments else 0\n",
    "        \n",
    "        # Calcular engagement\n",
    "        post_data['engagement_score'] = post_data['likes'] * 2 + post_data['comentarios'] * 3\n",
    "        \n",
    "        blog_data['articulos'].append(post_data)\n",
    "    \n",
    "    # 3. Estad√≠sticas generales\n",
    "    blog_data['estadisticas'] = {\n",
    "        'total_articulos': len(blog_data['articulos']),\n",
    "        'articulos_destacados': sum(1 for a in blog_data['articulos'] if a['es_destacado']),\n",
    "        'total_likes': sum(a['likes'] for a in blog_data['articulos']),\n",
    "        'total_comentarios': sum(a['comentarios'] for a in blog_data['articulos']),\n",
    "        'categorias': list(set(a['categoria'] for a in blog_data['articulos'])),\n",
    "        'autores': list(set(a['autor'] for a in blog_data['articulos'])),\n",
    "        'tags_unicos': list(set(tag for a in blog_data['articulos'] for tag in a['tags']))\n",
    "    }\n",
    "    \n",
    "    # Art√≠culo m√°s popular\n",
    "    if blog_data['articulos']:\n",
    "        mas_popular = max(blog_data['articulos'], key=lambda x: x['engagement_score'])\n",
    "        blog_data['estadisticas']['articulo_mas_popular'] = mas_popular['titulo']\n",
    "    \n",
    "    return blog_data\n",
    "\n",
    "# Ejecutar el scraper\n",
    "resultado = scraper_completo(html_blog)\n",
    "\n",
    "# Mostrar resultados\n",
    "print(f\"üìö BLOG: {resultado['titulo_sitio']}\\n\")\n",
    "\n",
    "print(\"üì∞ ART√çCULOS EXTRA√çDOS:\")\n",
    "for i, art in enumerate(resultado['articulos'], 1):\n",
    "    destacado = \"‚≠ê\" if art['es_destacado'] else \"  \"\n",
    "    print(f\"\\n{destacado} {i}. {art['titulo']}\")\n",
    "    print(f\"      ID: {art['id']} | Categor√≠a: {art['categoria']}\")\n",
    "    print(f\"      Autor: {art['autor']} | Fecha: {art['fecha']}\")\n",
    "    print(f\"      Tiempo de lectura: {art['tiempo_lectura']}\")\n",
    "    print(f\"      Tags: {', '.join(art['tags'])}\")\n",
    "    print(f\"      Engagement: {art['likes']} ‚ù§Ô∏è | {art['comentarios']} üí¨\")\n",
    "    print(f\"      Score: {art['engagement_score']} puntos\")\n",
    "    print(f\"      Preview: {art['preview']}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üìä ESTAD√çSTICAS GENERALES:\")\n",
    "stats = resultado['estadisticas']\n",
    "print(f\"   ‚Ä¢ Total de art√≠culos: {stats['total_articulos']}\")\n",
    "print(f\"   ‚Ä¢ Art√≠culos destacados: {stats['articulos_destacados']}\")\n",
    "print(f\"   ‚Ä¢ Total de likes: {stats['total_likes']}\")\n",
    "print(f\"   ‚Ä¢ Total de comentarios: {stats['total_comentarios']}\")\n",
    "print(f\"   ‚Ä¢ Categor√≠as: {', '.join(stats['categorias'])}\")\n",
    "print(f\"   ‚Ä¢ Autores: {', '.join(stats['autores'])}\")\n",
    "print(f\"   ‚Ä¢ Tags √∫nicos: {', '.join(stats['tags_unicos'])}\")\n",
    "if 'articulo_mas_popular' in stats:\n",
    "    print(f\"   ‚Ä¢ Art√≠culo m√°s popular: {stats['articulo_mas_popular']}\")\n",
    "\n",
    "print(\"\\nüéâ ¬°Scraper completo ejecutado exitosamente!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Resumen y Conclusiones üìö\n",
    "\n",
    "### üéØ Lo que has aprendido:\n",
    "\n",
    "1. **Encadenamiento de XPath**\n",
    "   - Dividir consultas complejas en partes manejables\n",
    "   - Reutilizar selectores para m√∫ltiples extracciones\n",
    "   - Debugging m√°s efectivo\n",
    "\n",
    "2. **Conversi√≥n XPath ‚Üî CSS**\n",
    "   - Equivalencias entre ambos sistemas\n",
    "   - Cu√°ndo usar cada uno\n",
    "   - Limitaciones y ventajas de cada m√©todo\n",
    "\n",
    "3. **T√©cnicas Avanzadas**\n",
    "   - Funciones XPath: contains(), starts-with(), position(), etc.\n",
    "   - Pseudo-clases CSS: :first-child, :nth-child, etc.\n",
    "   - Selectores de atributos avanzados\n",
    "\n",
    "4. **Integraci√≥n con Scrapy**\n",
    "   - Usar Scrapy Selector con requests\n",
    "   - Combinar XPath y CSS en el mismo proyecto\n",
    "   - Optimizaci√≥n de consultas\n",
    "\n",
    "### üí° Mejores Pr√°cticas:\n",
    "\n",
    "- **Especificidad**: Ser lo m√°s espec√≠fico posible sin ser fr√°gil\n",
    "- **Robustez**: Preferir IDs y atributos data-* cuando sea posible\n",
    "- **Modularidad**: Usar encadenamiento para c√≥digo m√°s mantenible\n",
    "- **Rendimiento**: Minimizar b√∫squedas repetidas\n",
    "- **Flexibilidad**: Combinar XPath y CSS seg√∫n convenga\n",
    "\n",
    "### üöÄ Pr√≥ximos Pasos:\n",
    "\n",
    "1. Practica con sitios web reales\n",
    "2. Experimenta con selectores m√°s complejos\n",
    "3. Aprende a manejar contenido din√°mico (JavaScript)\n",
    "4. Explora frameworks como Scrapy en profundidad\n",
    "5. Implementa manejo de errores robusto\n",
    "\n",
    "### üìå Tabla de Referencia R√°pida:\n",
    "\n",
    "| Tarea | XPath | CSS |\n",
    "|-------|-------|-----|\n",
    "| Por ID | `//div[@id=\"main\"]` | `#main` |\n",
    "| Por clase | `//div[@class=\"content\"]` | `.content` |\n",
    "| Hijo directo | `//div/p` | `div > p` |\n",
    "| Descendiente | `//div//p` | `div p` |\n",
    "| Por texto | `//p[contains(text(), \"hello\")]` | No disponible |\n",
    "| Primer elemento | `//li[1]` | `li:first-child` |\n",
    "| Atributo | `//a/@href` | No directamente |\n",
    "| Padre | `//span/parent::div` | No disponible |\n",
    "\n",
    "¬°Felicidades por completar esta lecci√≥n avanzada! üéâ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}